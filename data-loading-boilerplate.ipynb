{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "impaired-governor",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataset import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "coupled-hollow",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_label_type_distribution(data_dict):\n",
    "    answer_types={}\n",
    "    for data in data_dict:\n",
    "        for label in data[\"label\"]:\n",
    "            label = label.lower()\n",
    "            if label in answer_types:\n",
    "                answer_types[label]+=1\n",
    "            else:\n",
    "                answer_types[label]=1\n",
    "    return answer_types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "large-excess",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_answer_type_distribution(data_dict):\n",
    "    answer_types={}\n",
    "    for data in data_dict:\n",
    "        if data[\"answer_type\"] in answer_types:\n",
    "            answer_types[data[\"answer_type\"]]+=1\n",
    "        else:\n",
    "            answer_types[data[\"answer_type\"]]=1\n",
    "    return answer_types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "judicial-ideal",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_question_type_distribution(data_dict):\n",
    "    question_types={}\n",
    "    for data in data_dict:\n",
    "        if data[\"question_type\"] in question_types:\n",
    "            question_types[data[\"question_type\"]]+=1\n",
    "        else:\n",
    "            question_types[data[\"question_type\"]]=1\n",
    "    return question_types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "angry-judgment",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dict = get_data_dictionary(\"train\")\n",
    "test_dict = get_data_dictionary(\"test\")\n",
    "val_dict = get_data_dictionary(\"val\")\n",
    "\n",
    "data_dict={}\n",
    "data_dict[\"train\"]=train_dict\n",
    "data_dict[\"test\"]=test_dict\n",
    "data_dict[\"val\"]=val_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "split-motorcycle",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train answer-type distribution\n",
      "{'other': 9887, 'yes/no': 9806, 'number': 62}\n",
      "val answer-type distribution\n",
      "{'other': 3123, 'yes/no': 3135, 'number': 21}\n",
      "test answer-type distribution\n",
      "{'other': 3352, 'yes/no': 3391, 'number': 18}\n"
     ]
    }
   ],
   "source": [
    "for mode in [\"train\",\"val\",\"test\"]:\n",
    "    print(mode+\" answer-type distribution\")\n",
    "    print(get_answer_type_distribution(data_dict[mode]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "constitutional-array",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = get_label_type_distribution(data_dict[\"train\"])\n",
    "y = sorted(x.items(), key=lambda item: item[1], reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "second-reading",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8867628448494053\n",
      "3237\n"
     ]
    }
   ],
   "source": [
    "s = sum(i for j,i in y[:1000])\n",
    "print(s/19755)\n",
    "print(len(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "collective-resolution",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading train images\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'img_to_array' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-fa3326d6f0c0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"train\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"val\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"test\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Loading \"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\" images\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mimg_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mload_image_from_dictionary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Total %d images loaded. Done!\"\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/UMass/Academics/Fall 2021/685/Project/repo/VQA-685/dataset.py\u001b[0m in \u001b[0;36mload_image_from_dictionary\u001b[0;34m(data_dict, mode)\u001b[0m\n\u001b[1;32m     34\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata_dict\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"img_id\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mimg_dict\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m                         \u001b[0mimg_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"img_id\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mimg_to_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mload_img\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"data/images/\"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\"/\"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"img_id\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\".jpg\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mimg_dict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'img_to_array' is not defined"
     ]
    }
   ],
   "source": [
    "img_dict={}\n",
    "for mode in [\"train\",\"val\",\"test\"]:\n",
    "    print(\"Loading \"+mode+\" images\")\n",
    "    img_dict[mode]=load_image_from_dictionary(data_dict[mode],mode)\n",
    "    print(\"Total %d images loaded. Done!\"%len(img_dict[mode].keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "impaired-guitar",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer, BertModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "medieval-plaza",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "timely-ultimate",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_texts=[\"Hi\",\"bB \"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "hawaiian-reflection",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_tokens = list(map(lambda t: ['[CLS]'] + tokenizer.tokenize(t)[:511], train_texts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "loving-savage",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['[CLS]', 'hi'], ['[CLS]', 'bb']]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ranking-adams",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_tokens_ids = list(map(tokenizer.convert_tokens_to_ids, train_tokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "optional-genealogy",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[101, 7632], [101, 22861]]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_tokens_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "traditional-leadership",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'size'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-1110cbc10e76>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_tokens_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpad_sequence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_tokens_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding_value\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m512\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m#, truncating=\"post\", padding=\"post\", dtype=\"int\")\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/venvs/box-env/lib/python3.9/site-packages/torch/nn/utils/rnn.py\u001b[0m in \u001b[0;36mpad_sequence\u001b[0;34m(sequences, batch_first, padding_value)\u001b[0m\n\u001b[1;32m    356\u001b[0m     \u001b[0;31m# assuming trailing dimensions and type of all the Tensors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    357\u001b[0m     \u001b[0;31m# in sequences are same and fetching those from sequences[0]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 358\u001b[0;31m     \u001b[0mmax_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msequences\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    359\u001b[0m     \u001b[0mtrailing_dims\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmax_size\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    360\u001b[0m     \u001b[0mmax_len\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ms\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msequences\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'size'"
     ]
    }
   ],
   "source": [
    "train_tokens_ids = pad_sequence(train_tokens_ids, padding_value=512)#, truncating=\"post\", padding=\"post\", dtype=\"int\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "conscious-leave",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn.utils.rnn import pad_sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "limiting-husband",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "52a443f09c1f4d4aafa2e4dc69ab6d46",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/420M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "bert = BertModel.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "existing-curtis",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[101, 7632], [101, 22861]]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_tokens_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "expired-klein",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "forward() got an unexpected keyword argument 'output_all_encoded_layers'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-ad6e4ca9d2d2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpooled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_tokens_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_all_encoded_layers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/venvs/box-env/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: forward() got an unexpected keyword argument 'output_all_encoded_layers'"
     ]
    }
   ],
   "source": [
    "y, pooled = bert(train_tokens_ids, output_all_encoded_layers=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "otherwise-better",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
